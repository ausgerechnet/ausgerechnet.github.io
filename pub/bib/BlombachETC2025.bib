@InProceedings{BlombachETC2025,
  author    = {Blombach, Andreas and Doan Dang, Bao Minh and Evert, Stephanie and Fuchs, Tamara and Heinrich, Philipp and Kalashnikova, Olena and Unjum, Naveed},
  title     = {Narrlangen at {S}em{E}val-2025 Task 10: Comparing (mostly) simple multilingual approaches to narrative classification},
  booktitle = {Proceedings of the 19th International Workshop on Semantic Evaluation (SemEval-2025)},
  year      = {2025},
  editor    = {Rosenthal, Sara and Ros{\'a}, Aiala and Ghosh, Debanjan and Zampieri, Marcos},
  pages     = {2240--2248},
  address   = {Vienna, Austria},
  month     = jul,
  publisher = {Association for Computational Linguistics},
  abstract  = {Our team focused on Subtask 2 (narrative classification) and tried several conceptually straightforward approaches: (1) prompt engineering of LLMs, (2) a zero-shot approach based on sentence similarities, (3) direct classification of fine-grained labels using SetFit, (4) fine-tuning encoder models on fine-grained labels, and (5) hierarchical classification using encoder models with two different classification heads. We list results for all systems on the development set, which show that the best approach was to fine-tune a pre-trained multilingual model, XLM-RoBERTa, with two additional linear layers and a softmax as classification head.},
  isbn      = {979-8-89176-273-2},
  url       = {https://aclanthology.org/2025.semeval-1.291/},
  note      = {SharedTask},
}